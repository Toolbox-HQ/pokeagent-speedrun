eval_checkpoints: [
  ".cache/pokeagent/checkpoints/early_game_agent/5b499486d21887611f62005c1c08280b91df05c5/checkpoint-2365/model.safetensors",
  ".cache/pokeagent/checkpoints/early_game_state_only_agent/5b499486d21887611f62005c1c08280b91df05c5/checkpoint-2365/model.safetensors",
  ".cache/pokeagent/checkpoints/agent/f457370742b493b7d6c5aa8a741bea35d62dc0d9/checkpoint-7400/model.safetensors",
  ".cache/pokeagent/checkpoints/state_only_agent/5b499486d21887611f62005c1c08280b91df05c5/checkpoint-7400/model.safetensors",
]

eval_architectures: [
  "default",
  "state_only",
  "default",
  "state_only"
]

lm_name_or_path: "Qwen/Qwen3-1.7B"
vision_name_or_path: "google/siglip-base-patch16-224"
output_dir: ".cache/pokeagent/checkpoints"
# these are unused flags if running a pure eval
num_train_epochs: 5
per_device_train_batch_size: 4
save_strategy: "steps"
save_steps: 500
save_total_limit: 10
learning_rate: 5.0e-5
weight_decay: 0.00001
adam_beta2: 0.95
warmup_ratio: 0.05
lr_scheduler_type: "linear"
logging_steps: 1
gradient_checkpointing: true
report_to: "wandb"
eval_strategy: "steps"
eval_steps: 370 # 1/4 epoch
dataloader_num_workers: 8
data_path: ".cache/pokeagent/intervals.json"